### Well hello there!

This repository is meant to provide an example for *forking* a repository on GitHub.

Creating a *fork* is producing a personal copy of someone else's project. Forks act as a sort of bridge between the original repository and your personal copy. You can submit *Pull Requests* to help make other people's projects better by offering your changes up to the original project. Forking is at the core of social coding at GitHub.

After forking this repository, you can make some changes to the project, and submit [a Pull Request](https://github.com/octocat/Spoon-Knife/pulls) as practice.

For some more information on how to fork a repository, [check out our guide, "Forking Projects""](http://guides.github.com/overviews/forking/). Thanks! :sparkling_heart:

| PROBLEM | PAPER | CODE |
| :---:         |     :---:      |          :---: |
| Classification| [“ResNet” Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)| Implemented in keras, pytorch, fastai |
| Detection     |[RetinaNet: Focal Loss for Dense Object Detection](https://arxiv.org/pdf/1708.02002.pdf)<br><br><br>[Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks](https://arxiv.org/pdf/1506.01497.pdf)<br><br><br> [SSD: Single Shot MultiBox Detector](https://arxiv.org/pdf/1512.02325.pdf)<br><br><br>[YOLOv3: An Incremental Improvement](https://pjreddie.com/media/files/papers/YOLOv3.pdf)|Part of FAIR’s [Detectron](https://github.com/facebookresearch/Detectron)<br><br><br>Part of [Tensorflow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)<br><br><br>Part of [Tensorflow Object Detection API](https://github.com/tensorflow/models/tree/master/research/object_detection)<br><br><br>[CODE](https://pjreddie.com/darknet/yolo/)|
|Semantic Segmentation| [“Deeplab v3” Rethinking Atrous Convolution for Semantic Image Segmentation](https://arxiv.org/pdf/1708.02002.pdf)|[CODE](https://github.com/tensorflow/models/tree/master/research/deeplab)|
|Instance Segmentation| [Mask R-CNN](https://arxiv.org/pdf/1703.06870.pdf)|[CODE](https://github.com/matterport/Mask_RCNN)|
|Human Pose Estimation| [OpenPose: Realtime Multi-Person 2D Pose Estimation using Part Affinity Fields](https://arxiv.org/pdf/1812.08008.pdf)|[CODE](https://github.com/CMU-Perceptual-Computing-Lab/openpose)|
|Hand Pose Estimation| [GANerated Hands for Real-Time 3D Hand Tracking from Monocular RGB](https://arxiv.org/pdf/1712.01057.pdf)| |
|Face Detection| [Selective Refinement Network for High Performance Face Detection](https://arxiv.org/pdf/1809.02693v1.pdf)|[CODE](https://github.com/ChiCheng123/SRN)|
|Face Recognition| [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/pdf/1503.03832v3.pdf)|[CODE](https://github.com/davidsandberg/facenet)|
|Tracking| [Fast Online Object Tracking and Segmentation: A Unifying Approach](https://arxiv.org/pdf/1812.05050.pdf)|[CODE](https://github.com/foolwood/SiamMask)|
|Depth Estimation| [Digging Into Self-Supervised Monocular Depth Estimation](https://arxiv.org/pdf/1806.01260v3.pdf)|[CODE](https://github.com/nianticlabs/monodepth2)|
|Structure from Motion|  |[opensfm](https://github.com/mapillary/OpenSfM)|
|Image Generation|[LARGE SCALE GAN TRAINING FOR HIGH FIDELITY NATURAL IMAGE SYNTHESIS](https://arxiv.org/pdf/1809.11096.pdf)| |
|Face Generation| [StyleGAN: A Style-Based Generator Architecture for Generative Adversarial Networks](https://arxiv.org/pdf/1812.04948.pdf)|[CODE](https://github.com/NVlabs/stylegan)|
|Image to Image| [Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/pdf/1703.10593.pdf)|[CODE](https://github.com/junyanz/pytorch-CycleGAN-and-pix2pix)|
|Style Transfer| [A Closed-form Solution to Photorealistic Image Stylization](https://arxiv.org/pdf/1802.06474v5.pdf)|[CODE](https://github.com/NVIDIA/FastPhotoStyle)|
|Keypoint Detection and Tracking| [SuperPoint: Self-Supervised Interest Point Detection and Description](http://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w9/DeTone_SuperPoint_Self-Supervised_Interest_CVPR_2018_paper.pdf)|[CODE](https://github.com/MagicLeapResearch/SuperPointPretrainedNetwork)|
|Image Captioning| [Bottom-Up and Top-Down Attention for Image Captioning and Visual Question Answering](https://arxiv.org/pdf/1707.07998v3.pdf)|[CODE](https://github.com/facebookresearch/pythia)|
|Text to Image| [StackGAN++: Realistic Image Synthesis with Stacked Generative Adversarial Networks](https://arxiv.org/pdf/1710.10916.pdf)|[CODE](https://github.com/hanzhanggit/StackGAN)|


